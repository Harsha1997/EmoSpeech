{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "class Model(object):\n",
    "\n",
    "    def __init__(self, save_path=None, name='Not Specified', **params):\n",
    "       \n",
    "        # Place holder for model\n",
    "        self.model = None\n",
    "        # Place holder on where to save the model\n",
    "        self.save_path = save_path\n",
    "        # Place holder for name of the model\n",
    "        self.name = name\n",
    "        # Model has been trained or not\n",
    "        self.trained = False\n",
    "\n",
    "    def train(self, x_train, y_train, x_val=None, y_val=None):\n",
    "       \n",
    "        self.model.fit(x_train, y_train)\n",
    "        self.trained = True\n",
    "        if self.save_path:\n",
    "            self.save_model()\n",
    "\n",
    "    def predict(self, data):\n",
    "       \n",
    "        if not self.trained:\n",
    "            sys.stderr.write(\"Model should be trained or loaded before doing predict\\n\")\n",
    "            sys.exit(-1)\n",
    "        return self.model.predict(data)\n",
    "\n",
    "    def restore_model(self, load_path=None):\n",
    "       \n",
    "        to_load = load_path or self.save_path\n",
    "        if to_load is None:\n",
    "            sys.stderr.write(\"Provide a path to load from or save_path of the model\\n\")\n",
    "            sys.exit(-1)\n",
    "        self.load_model(to_load)\n",
    "        self.trained = True\n",
    "\n",
    "    def load_model(self, to_load):\n",
    "        \n",
    "        # This will be specific to model so should be implemented by child classes\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def save_model(self):\n",
    "       \n",
    "        # This will be specific to model so should be implemented by child classes\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def evaluate(self, x_test, y_test):\n",
    "        \n",
    "        # This will be specific to model so should be implemented by child classes\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import scipy.io.wavfile as wav\n",
    "import os\n",
    "import speechpy\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class_labels = ['Neutral', 'Angry', 'Happy', 'Sad']\n",
    "\n",
    "mslen = 32000  # Empirically calculated for the given dataset\n",
    "\n",
    "\n",
    "def read_wav(filename):\n",
    "   \n",
    "    return wav.read(filename)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm,\n",
    "                          target_names,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=None,\n",
    "                          normalize=True):\n",
    "    \"\"\"\n",
    "    given a sklearn confusion matrix (cm), make a nice plot\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n",
    "\n",
    "    target_names: given classification classes such as [0, 1, 2]\n",
    "                  the class names, for example: ['high', 'medium', 'low']\n",
    "\n",
    "    title:        the text to display at the top of the matrix\n",
    "\n",
    "    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n",
    "                  see http://matplotlib.org/examples/color/colormaps_reference.html\n",
    "                  plt.get_cmap('jet') or plt.cm.Blues\n",
    "\n",
    "    normalize:    If False, plot the raw numbers\n",
    "                  If True, plot the proportions\n",
    "\n",
    "    Usage\n",
    "    -----\n",
    "    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n",
    "                                                              # sklearn.metrics.confusion_matrix\n",
    "                          normalize    = True,                # show proportions\n",
    "                          target_names = y_labels_vals,       # list of names of the classes\n",
    "                          title        = best_estimator_name) # title of graph\n",
    "\n",
    "    Citiation\n",
    "    ---------\n",
    "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import itertools\n",
    "\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def get_data(dataset_path, flatten=True, mfcc_len=39):\n",
    "\n",
    "    data = []\n",
    "    labels = []\n",
    "    max_fs = 0\n",
    "    s = 0\n",
    "    cnt = 0\n",
    "    cur_dir = os.getcwd()\n",
    "    print('curdir', cur_dir)\n",
    "    os.chdir(dataset_path)\n",
    "    for i, directory in enumerate(class_labels):\n",
    "        print(\"started reading folder\", directory)\n",
    "        os.chdir(directory)\n",
    "        for filename in os.listdir('.'):\n",
    "                fs, signal = read_wav(filename)\n",
    "                max_fs = max(max_fs, fs)\n",
    "                s_len = len(signal)\n",
    "#                 print(s_len)\n",
    "           \n",
    "                if s_len < mslen:\n",
    "                    pad_len = mslen - s_len\n",
    "                    pad_rem = pad_len % 2\n",
    "                    pad_len //= 2\n",
    "                    signal = np.pad(signal, (pad_len, pad_len + pad_rem), 'constant', constant_values=0)\n",
    "                else:\n",
    "                    pad_len = s_len - mslen\n",
    "                    pad_len //= 2\n",
    "                    signal = signal[pad_len:pad_len + mslen]\n",
    "                mfcc = speechpy.feature.mfcc(signal, fs, num_cepstral=mfcc_len)\n",
    "#                 print(mfcc.shape)\n",
    "                \n",
    "                if flatten:\n",
    "                    # Flatten the data\n",
    "                    mfcc = mfcc.flatten()\n",
    "                data.append(mfcc)\n",
    "                labels.append(i)\n",
    "                cnt += 1\n",
    "        print(\"ended reading folder\", directory)\n",
    "        os.chdir('..')\n",
    "    os.chdir(cur_dir)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "    return np.array(x_train), np.array(x_test), np.array(y_train), np.array(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This file contains classes which implement deep neural networks namely CNN and LSTM\n",
    "\"\"\"\n",
    "import sys\n",
    "import keras\n",
    "from keras import Sequential\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import LSTM as lstm, Dense, Dropout, Conv2D, Flatten, \\\n",
    "    BatchNormalization, Activation, MaxPooling2D\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "class DNN(Model):\n",
    "   \n",
    "\n",
    "    def __init__(self, input_shape, num_classes, **params):\n",
    "       \n",
    "        super(DNN, self).__init__(**params)\n",
    "        self.input_shape = input_shape\n",
    "        self.model = Sequential()\n",
    "        self.make_default_model()\n",
    "        self.model.add(Dense(num_classes, activation='softmax'))\n",
    "        self.model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n",
    "        print(self.model.summary())\n",
    "        self.save_path = 'models/' + self.name + '_best_model_ravdess_test.h5'\n",
    "\n",
    "    def load_model(self, to_load):\n",
    "        try:\n",
    "            self.model.load_weights(to_load)\n",
    "        except:\n",
    "            sys.stderr.write(\"Invalid saved file provided\")\n",
    "            sys.exit(-1)\n",
    "\n",
    "    def save_model(self):\n",
    "        self.model.save_weights(self.save_path)\n",
    "\n",
    "    def evaluate(self, x_test, y_test):\n",
    "        y_pred = self.predict(x_test)\n",
    "        print(y_pred)\n",
    "        print(y_pred.argmax(1))\n",
    "        print(y_test)\n",
    "        print('Accuracy= ',keras.metrics.categorical_accuracy(y_test,y_pred))\n",
    "        print('Accuracy =', self.model.evaluate(x_test, y_test)[1])\n",
    "        cm = confusion_matrix(y_pred=y_pred.argmax(1), y_true=y_test.argmax(1))\n",
    "        plot_confusion_matrix(cm,normalize=False,target_names =['Neutral', 'Angry', 'Happy', 'Sad'],title = \"Confusion Matrix\")\n",
    "\n",
    "    def train(self, x_train, y_train, x_val=None, y_val=None):\n",
    "        cnt = 0\n",
    "        best_acc = 0\n",
    "        for i in range(50):\n",
    "            p = np.random.permutation(len(x_train))\n",
    "            print(\"x_train shape\",x_train.shape)\n",
    "            x_train = x_train[p]\n",
    "            y_train = y_train[p]\n",
    "            cnt = cnt+1\n",
    "            print(\"hello inside x_train1 what are you doing here\",x_train.shape)\n",
    "            early_stopping=EarlyStopping(monitor='val_categorical_accuracy',mode='max')\n",
    "            self.model.fit(x_train, y_train, batch_size=32, epochs=4,validation_split=0.2,callbacks=[early_stopping])\n",
    "            loss, acc = self.model.evaluate(x_val, y_val)\n",
    "            print(\"accuracy\",acc)\n",
    "            if acc > best_acc:\n",
    "                best_acc = acc\n",
    "        self.trained = True\n",
    "        print(cnt)\n",
    "\n",
    "    def make_default_model(self):\n",
    "        \"\"\"\n",
    "        Make the model with default hyper parameters\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "\n",
    "class CNN(DNN):\n",
    "    \"\"\"\n",
    "    This class handles CNN for speech emotion recognitions\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_shape, num_classes, **params):\n",
    "        params['name'] = 'CNN'\n",
    "        super(CNN, self).__init__(input_shape, num_classes, **params)\n",
    "\n",
    "    def make_default_model(self):\n",
    "        self.model.add(Conv2D(8, (13, 13),\n",
    "                              input_shape=(self.input_shape[0], self.input_shape[1], 1)))\n",
    "        self.model.add(BatchNormalization(axis=-1))\n",
    "        self.model.add(Activation('relu'))\n",
    "        self.model.add(MaxPooling2D(pool_size=(2, 1)))\n",
    "        self.model.add(Flatten())\n",
    "        self.model.add(Dense(64))\n",
    "        self.model.add(BatchNormalization())\n",
    "        self.model.add(Activation('relu'))\n",
    "        self.model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "class LSTM(DNN):\n",
    "    \"\"\"\n",
    "    This class handles CNN for speech emotion recognitions\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_shape, num_classes, **params):\n",
    "        params['name'] = 'LSTM'\n",
    "        super(LSTM, self).__init__(input_shape, num_classes, **params)\n",
    "\n",
    "    def make_default_model(self):\n",
    "        self.model.add(lstm(128, input_shape=(self.input_shape[0], self.input_shape[1])))\n",
    "        self.model.add(Dropout(0.5))\n",
    "        self.model.add(Dense(32, activation='relu'))\n",
    "        self.model.add(Dense(16, activation='tanh'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "\n",
    "class MLModel(Model):\n",
    "  \n",
    "\n",
    "    def __init__(self, **params):\n",
    "        super(MLModel, self).__init__(**params)\n",
    "        self.save_path = 'models/' + self.name + '_best_model_testing.h5' \n",
    "\n",
    "    def evaluate(self, x_test, y_test):\n",
    "        y_pred = self.predict(x_test)\n",
    "        print('Accuracy',accuracy_score(y_pred=y_pred, y_true=y_test))\n",
    "        cm = confusion_matrix(y_pred=y_pred, y_true=y_test)\n",
    "        plot_confusion_matrix(cm,normalize=False,target_names =['Neutral', 'Angry', 'Happy', 'Sad'],title = \"Confusion Matrix\")\n",
    "\n",
    "    def save_model(self):\n",
    "        pickle.dump(self.model, open(self.save_path, \"wb\"))\n",
    "\n",
    "    def load_model(self):\n",
    "        try:\n",
    "            print('reading model')\n",
    "            print(self.save_path)\n",
    "            self.model = pickle.load(open(self.save_path, \"rb\"))\n",
    "        except:\n",
    "            sys.stderr.write(\"Invalid saved file provided\")\n",
    "            sys.exit(-1)\n",
    "\n",
    "\n",
    "class SVM(MLModel):\n",
    "\n",
    "\n",
    "    def __init__(self, **params):\n",
    "        params['name'] = 'SVM'\n",
    "        super(SVM, self).__init__(**params)\n",
    "        self.model = LinearSVC(multi_class='crammer_singer')\n",
    "\n",
    "\n",
    "class RF(MLModel):\n",
    "\n",
    "    def __init__(self, **params):\n",
    "        params['name'] = 'Random Forest'\n",
    "        super(RF, self).__init__(**params)\n",
    "        self.model = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "\n",
    "class NN(MLModel):\n",
    "    \"\"\"\n",
    "    NN implements use of Neural networks for speech emotion recognition\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, **params):\n",
    "        params['name'] = 'Neural Network'\n",
    "        super(NN, self).__init__(**params)\n",
    "        self.model = MLPClassifier(activation='logistic', verbose=True,\n",
    "                                   hidden_layer_sizes=(512,), batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curr_dir /home/deepak/Desktop/project\n",
      "reading model\n",
      "models/SVM_best_model.h5\n",
      "SVM model loaded\n",
      "(7722,)\n",
      "(7722,)\n",
      "(7722,)\n",
      "[2 2 2]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This example script uses the library `speechemotionrecognition` and do the training and evaluating the models on\n",
    "\"\"\"\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import scipy.io.wavfile as wav\n",
    "import os\n",
    "import speechpy\n",
    "import numpy as np\n",
    "dataset_path = 'dataset'\n",
    "mslen = 32000 \n",
    "\n",
    "def dnn_example():\n",
    "    x_train, x_test, y_train, y_test = get_data(dataset_path=dataset_path, flatten=False)\n",
    "    print(y_train.shape)\n",
    "    y_train = np_utils.to_categorical(y_train)\n",
    "    print(y_train.shape)\n",
    "    y_test = np_utils.to_categorical(y_test)\n",
    "    print('Starting LSTM')\n",
    "    model = LSTM(input_shape=x_train[0].shape, num_classes=len(class_labels))\n",
    "    model.train(x_train, y_train, x_test, y_test)\n",
    "    model.evaluate(x_test, y_test)\n",
    "    model.save_model()\n",
    "    print('LSTM Done\\n Starting CNN')\n",
    "    in_shape = x_train[0].shape\n",
    "    x_train = x_train.reshape(x_train.shape[0], in_shape[0], in_shape[1], 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], in_shape[0], in_shape[1], 1)\n",
    "    model = CNN(input_shape=x_train[0].shape, num_classes=len(class_labels))\n",
    "    model.train(x_train, y_train, x_test, y_test)\n",
    "    model.evaluate(x_test, y_test)\n",
    "    print('CNN Done')\n",
    "\n",
    "\n",
    "def ml_example():\n",
    "    x_train, x_test, y_train, y_test = get_data(dataset_path=dataset_path)\n",
    "    print(x_train.shape)\n",
    "    models = [NN, RF, SVM]\n",
    "    for M in models:\n",
    "        model = M()\n",
    "        print('Starting', model.name)\n",
    "        model.train(x_train, y_train)\n",
    "        model.evaluate(x_test, y_test)\n",
    "        count=0\n",
    "        for val in y_test:\n",
    "            if val == 0 :\n",
    "                count=count+1\n",
    "        print(count)       \n",
    "        model.save_model()\n",
    "        print(model.name, 'Done')\n",
    "\n",
    "def loadsvm():\n",
    "    obj = SVM()\n",
    "    cur_dir = os.getcwd()\n",
    "    print('curr_dir',cur_dir)\n",
    "    obj.save_path = \"models/SVM_best_model.h5\"\n",
    "    obj.load_model()\n",
    "    print('SVM model loaded')\n",
    "    os.chdir('test')\n",
    "    max_fs = 0\n",
    "    data = []\n",
    "    for filename in os.listdir('.'):\n",
    "        fs, signal = wav.read(filename)\n",
    "        max_fs = max(max_fs, fs)\n",
    "        s_len = len(signal)\n",
    "        # pad the signals to have same size if lesser than required\n",
    "        # else slice them\n",
    "        if s_len < mslen:\n",
    "            pad_len = mslen - s_len\n",
    "            pad_rem = pad_len % 2\n",
    "            pad_len //= 2\n",
    "            signal = np.pad(signal, (pad_len, pad_len + pad_rem), 'constant', constant_values=0)\n",
    "        else:\n",
    "            pad_len = s_len - mslen\n",
    "            pad_len //= 2\n",
    "            signal = signal[pad_len:pad_len + mslen]\n",
    "        mfcc = speechpy.feature.mfcc(signal, fs, num_cepstral=39)\n",
    "        mfcc = mfcc.flatten()\n",
    "        print(mfcc.shape)\n",
    "        data.append(mfcc)\n",
    "    print(obj.model.predict(data))\n",
    "\n",
    "def loadlstm():\n",
    "    print('LSTM model loaded')\n",
    "    print('Predicting on new data')\n",
    "    max_fs = 0\n",
    "    data = []\n",
    "    cur_dir = os.getcwd()\n",
    "    print('curr_dir',cur_dir)\n",
    "    os.chdir('test')\n",
    "    obj = LSTM(input_shape=(198,39), num_classes=len(class_labels))\n",
    "    obj.load_model('models/best_model_LSTM.h5')\n",
    "    os.chdir('test')\n",
    "    for filename in os.listdir('.'):\n",
    "        fs, signal = wav.read(filename)\n",
    "        max_fs = max(max_fs, fs)\n",
    "        s_len = len(signal)\n",
    "        if s_len < mslen:\n",
    "            pad_len = mslen - s_len\n",
    "            pad_rem = pad_len % 2\n",
    "            pad_len //= 2\n",
    "            signal = np.pad(signal, (pad_len, pad_len + pad_rem), 'constant', constant_values=0)\n",
    "        else:\n",
    "            pad_len = s_len - mslen\n",
    "            pad_len //= 2\n",
    "            signal = signal[pad_len:pad_len + mslen]\n",
    "        mfcc = speechpy.feature.mfcc(signal, fs, num_cepstral=39)\n",
    "        print(mfcc.shape)\n",
    "        data.append(mfcc)\n",
    "    print(np.array(data).shape)\n",
    "    print(obj.model.predict(np.array(data)))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    loadsvm()\n",
    "    #ml_example()\n",
    "    #dnn_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curr_dir /home/deepak/Desktop/project\n"
     ]
    }
   ],
   "source": [
    "cur_dir = os.getcwd()\n",
    "print('curr_dir',cur_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
